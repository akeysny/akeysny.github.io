---
layout: post
title: "Web Application Security"
subtitle: "Overview of Cross-Site Scripting (XSS)"
background: '/img/posts/web-security/status-vs-dynamic.jpeg'
---

## Background 
Of the numerous vulnerabilities related to browser-based web applications, cross-site scripting (XSS) is one of the most common and damaging vulnerabilities. The browser is a sophisticated piece of software, not just because it must render content efficiently and portably, but it must also execute associated JavaScript. As a general rule, any system that executes code can be made to execute malicious code if proper protections aren't used. XSS is a technique in which an attacker is able to "trick" a browser into executing malicious JavaScript that's not part of the legitimate page. Even though web developers have known about it for years, it's still easy to let an XSS vulnerability slip through the cracks.


![IMDb page](/img/posts/web-security/cyber.jpeg)

## Types of XSS
There are three types of Cross-Site Scripting.

- Reflected

Data from URLs or forms
Runs immediately when data is received

As an example, imagine a search box at the top of a website. When a user submits a search term, the application searches the database for products matching that term. If no products are found, it responds with:

{% highlight ruby %}<h1>No results were found for: <?php echo $term; ?></h1>{% endhighlight ruby %}

If the search request was:

{% highlight ruby %}GET /search.php?term=candy{% endhighlight ruby %}

The application would return:

{% highlight ruby %}<h1>No results were found for: candy</h1>{% endhighlight ruby %}

Notice that the data being submitted in the URL query is not being sanitized to remove or disable JavaScript before it is output to HTML.

- Stored

Data from database, cookies, and sessions
Runs later when data is retrieved

- DOM-based

Data generated by JavaScript
Runs when user triggers JavaScript events

## A Positive XSS Prevention Model

This article treats an HTML page like a template, with slots where a developer is allowed to put untrusted data. These slots cover the vast majority of the common places where a developer might want to put untrusted data. Putting untrusted data in other places in the HTML is not allowed. This is an "allow list" model, that denies everything that is not specifically allowed.

Given the way browsers parse HTML, each of the different types of slots has slightly different security rules. When you put untrusted data into these slots, you need to take certain steps to make sure that the data does not break out of that slot into a context that allows code execution. In a way, this approach treats an HTML document like a parameterized database query - the data is kept in specific places and is isolated from code contexts with encoding.

This document sets out the most common types of slots and the rules for putting untrusted data into them safely. Based on the various specifications, known XSS vectors, and a great deal of manual testing with all the popular browsers, we have determined that the rules proposed here are safe.

The slots are defined and a few examples of each are provided. Developers SHOULD NOT put data into any other slots without a very careful analysis to ensure that what they are doing is safe. Browser parsing is extremely tricky and many innocuous looking characters can be significant in the right context.

## Why Can't I Just HTML Entity Encode Untrusted Data

HTML entity encoding is okay for untrusted data that you put in the body of the HTML document, such as inside a {% highlight ruby %}<div>{% endhighlight ruby %} tag. It even sort of works for untrusted data that goes into attributes, particularly if you're religious about using quotes around your attributes. 

But HTML entity encoding doesn't work if you're putting untrusted data inside a {% highlight ruby %}<script>{% endhighlight ruby %} tag anywhere, or an event handler attribute like onmouseover, or inside CSS, or in a URL. So even if you use an HTML entity encoding method everywhere, you are still most likely vulnerable to XSS. You MUST use the encode syntax for the part of the HTML document you're putting untrusted data into. That's what the rules below are all about.

## You Need a Security Encoding Library

Writing these encoders is not tremendously difficult, but there are quite a few hidden pitfalls. For example, you might be tempted to use some of the escaping shortcuts like {% highlight ruby %}\"{% endhighlight ruby %} in JavaScript. However, these values are dangerous and may be misinterpreted by the nested parsers in the browser. You might also forget to escape the escape character, which attackers can use to neutralize your attempts to be safe. OWASP recommends using a security-focused encoding library to make sure these rules are properly implemented.

## RULE #0 - Never Insert Untrusted Data Except in Allowed Locations

The first rule is to deny all - don't put untrusted data into your HTML document unless it is within one of the slots defined in Rule #1 through Rule #5. The reason for Rule #0 is that there are so many strange contexts within HTML that the list of encoding rules gets very complicated. We can't think of any good reason to put untrusted data in these contexts. This includes "nested contexts" like a URL inside a JavaScript -- the encoding rules for those locations are tricky and dangerous.

If you insist on putting untrusted data into nested contexts, please do a lot of cross-browser testing and let us know what you find out.

Directly in a script:

{% highlight ruby %}<script>...NEVER PUT UNTRUSTED DATA HERE...</script>{% endhighlight ruby %}

Inside an HTML comment:

{% highlight ruby %}<!--...NEVER PUT UNTRUSTED DATA HERE...-->{% endhighlight ruby %}

In an attribute name:

{% highlight ruby %}<div ...NEVER PUT UNTRUSTED DATA HERE...=test />{% endhighlight ruby %}

In a tag name:

{% highlight ruby %}<NEVER PUT UNTRUSTED DATA HERE... href="/test" />{% endhighlight ruby %}

Directly in CSS:

{% highlight ruby %}<style>
...NEVER PUT UNTRUSTED DATA HERE...
</style>{% endhighlight ruby %}




